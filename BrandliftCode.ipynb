{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebdc389",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install VIM\n",
    "!pip install naniar\n",
    "!pip install missMDA\n",
    "!pip install Amelia\n",
    "!pip install mice\n",
    "!pip install missForest\n",
    "!pip install FactoMineR\n",
    "!pip install Tidyverse\n",
    "\n",
    "# Python code equivalent of R code\n",
    "# Note: Some packages may need to be installed via pip or conda\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from VIM import impute\n",
    "from naniar import miss_var_summary, miss_case_summary\n",
    "from missMDA import imputePCA\n",
    "from Amelia import amelia\n",
    "from mice import MICE\n",
    "from missForest import missForest\n",
    "from FactoMineR import PCA\n",
    "from Tidyverse import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16d9a99",
   "metadata": {},
   "source": [
    "## Imputation Technique ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6053793",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# data = pd.read_csv(\"~/Downloads/Chalice Family Dollar Q4 2022 (Raw) (8).csv\")\n",
    "# data = pd.read_csv(\"~/Downloads/Chalice Family Dollar Q4 2022 (Raw).csv\")\n",
    "\n",
    "# convert data to a pandas DataFrame\n",
    "data = pd.DataFrame(data)\n",
    "data = data.apply(lambda x: pd.to_numeric(x, errors=\"coerce\"), axis=0) # convert all columns to numeric type\n",
    "\n",
    "# custom = pd.DataFrame(data.iloc[:, 16])\n",
    "# custom = pd.DataFrame(data.iloc[:, 18])\n",
    "custom = pd.DataFrame(data.iloc[:, 12])\n",
    "\n",
    "# custom = pd.DataFrame(data.iloc[:, 16])\n",
    "\n",
    "custom = custom.str.split(\",\", expand=True)\n",
    "custom.columns = [\"c1\", \"c2\", \"c3\", \"c4\", \"c5\"]\n",
    "\n",
    "custom[[\"var\", \"c1\"]] = custom[\"c1\"].str.split(\":\", expand=True)\n",
    "custom[\"c1\"] = custom[\"c1\"].apply(lambda x: re.sub('[[:punct:] ]+', ' ', x))\n",
    "\n",
    "custom[[\"var\", \"c2\"]] = custom[\"c2\"].str.split(\":\", expand=True)\n",
    "custom[\"c2\"] = custom[\"c2\"].apply(lambda x: re.sub('[[:punct:] ]+', ' ', x))\n",
    "\n",
    "custom[[\"var\", \"c3\"]] = custom[\"c3\"].str.split(\":\", expand=True)\n",
    "custom[\"c3\"] = custom[\"c3\"].apply(lambda x: re.sub('[[:punct:] ]+', ' ', x))\n",
    "\n",
    "custom[[\"var\", \"c4\"]] = custom[\"c4\"].str.split(\":\", expand=True)\n",
    "custom[\"c4\"] = custom[\"c4\"].apply(lambda x: re.sub('[[:punct:] ]+', ' ', x))\n",
    "\n",
    "custom[[\"var\", \"c5\"]] = custom[\"c5\"].str.split(\":\", expand=True)\n",
    "custom[\"c5\"] = custom[\"c5\"].apply(lambda x: re.sub('[[:punct:] ]+', ' ', x))\n",
    "\n",
    "custom = custom.drop(columns=[\"var\"])\n",
    "data = pd.concat([data, custom], axis=1)\n",
    "\n",
    "# Predictive mean matching (multiple imputation)\n",
    "data = data.replace(\"\", np.nan)\n",
    "\n",
    "# df = data.iloc[:, 14:23].join(data.iloc[:, 86:90])\n",
    "# df = data.iloc[:, 18:28].join(data.iloc[:, 86:90])\n",
    "# df = data.iloc[:, 20:30].join(data.iloc[:, 76:80])\n",
    "df = data.iloc[:, 14:23]\n",
    "\n",
    "##yaml, \"column names for the change in the config file\"\n",
    "##test out in the data bricks (hold out with cv = 6)\n",
    "\n",
    "final = data.drop(columns=df.columns)\n",
    "\n",
    "non_miss = df.notna().sum(axis=1)\n",
    "m = missForest(df.values, ntree=100, parallel=True, variablewise=False, maxiter=10, minprop=0.1)\n",
    "imputed_df = pd.DataFrame(m[\"ximp\"])\n",
    "imputed_df.columns = df.columns\n",
    "final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad11e242",
   "metadata": {},
   "source": [
    "## Brand Lift Code ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe81d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import geopandas as gpd\n",
    "import mapclassify\n",
    "from mapclassify import Quantiles, UserDefined, NaturalBreaks, EqualInterval\n",
    "import mapview\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import rasterio\n",
    "import rasterstats\n",
    "from rasterstats import zonal_stats\n",
    "import os\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import datetime\n",
    "import string\n",
    "import re\n",
    "import openpyxl\n",
    "import likert\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2898abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(\"final.csv\")\n",
    "\n",
    "creative = data[['Creative.Name']]\n",
    "creative = creative['Creative.Name'].str.split(pat='-', n=-1, expand=True)\n",
    "creative = creative.iloc[:, [1, 2]]\n",
    "creative.columns = [\"creativename\", \"creativeduration\"]\n",
    "creative['creativeduration'][creative['creativeduration'].str.contains('15')] = \"15s\"\n",
    "creative['creativeduration'][creative['creativeduration'].str.contains('6')] = \"6s\"\n",
    "creative['creativeduration'][creative['creativeduration'].str.contains('30')] = \"30s\"\n",
    "\n",
    "data = pd.concat([data, creative], axis=1)\n",
    "\n",
    "ZipCodeSourceFile = \"http://download.geonames.org/export/zip/US.zip\"\n",
    "response = requests.get(ZipCodeSourceFile)\n",
    "ZipCodes = pd.read_csv(BytesIO(response.content), sep=\"\\t\", header=None)\n",
    "ZipCodes = ZipCodes.iloc[:, [1, 2, 3, 4, 5, 9, 10, 11]]\n",
    "\n",
    "df = pd.merge(data, ZipCodes, how='left', left_on='Demo.ZIP', right_on=1)\n",
    "df = df.drop(1, axis=1)\n",
    "\n",
    "df['date'] = pd.to_datetime(df['Response.Date'], format=\"%Y-%m-%d\")\n",
    "df[['date', 'timezone']] = df['date'].astype(str).str.split(\" \", expand=True)\n",
    "df['date'] = pd.to_datetime(df['date'], format=\"%Y-%m-%d\")\n",
    "\n",
    "df['week'] = df['date'].dt.strftime('%V').astype(int)\n",
    "df['week'] = np.where(df['week'] == 1, 9, df['week'])\n",
    "df['week'] = np.where(df['week'] == 2, 10, df['week'])\n",
    "df['week'] = np.where(df['week'] == 3, 11, df['week'])\n",
    "df['week'] = np.where(df['week'] == 4, 12, df['week'])\n",
    "df['week'] = np.where(df['week'] == 5, 13, df['week'])\n",
    "\n",
    "df['week'] = np.where(df['week'] == 44, 1, df['week'])\n",
    "df['week'] = np.where(df['week'] == 45, 2, df['week'])\n",
    "df['week'] = np.where(df['week'] == 46, 3, df['week'])\n",
    "df['week'] = np.where(df['week'] == 47, 4, df['week'])\n",
    "df['week'] = np.where(df['week'] == 48, 5, df['week'])\n",
    "df['week'] = np.where(df['week'] == 49, 6, df['week'])\n",
    "df['week'] = np.where(df['week'] == 50, 7, df['week'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f9daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['week'] = pd.to_numeric(df['week'])\n",
    "df = df.sort_values(by=['week'])\n",
    "\n",
    "week_names = {1: '11/02/22', 2: '11/07/22', 3: '11/14/22', 4: '11/21/22', 5: '11/28/22', \n",
    "              6: '12/05/22', 7: '12/12/22', 8: '12/19/22', 9: '01/05/23', 10: '01/09/23', \n",
    "              11: '01/16/23', 12: '01/23/23', 13: '01/28/23'}\n",
    "df['Weekname'] = df['week'].map(week_names)\n",
    "\n",
    "df = df[df['date'] >= '2023-01-05']\n",
    "\n",
    "df['Demo.Age'] = pd.to_numeric(df['Demo.Age'])\n",
    "age_bins = [0, 18, 24, 34, 44, 54, 64, float('inf')]\n",
    "age_labels = ['0-18', '19-24', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "df['Age Group'] = pd.cut(df['Demo.Age'], bins=age_bins, labels=age_labels, include_lowest=True)\n",
    "\n",
    "df = df.sort_values(by=['Demo.State', 'Age Group', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b764b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dplython import *\n",
    "\n",
    "brand = df[df['Family.Dollar..Brand.Awareness'] == '2']\n",
    "\n",
    "\n",
    "m = (DplyFrame(brand)\n",
    "     .filter_by(Group=\"Exposed\")\n",
    "     .group_by('week', 'Demo.State', 'Strata')\n",
    "     .mutate(Total_exposed=X.Weight.sum())\n",
    "     .ungroup()\n",
    "     .group_by('week', 'Demo.State')\n",
    "     .mutate(Total_exposed_strata=X.Total_exposed.sum())\n",
    "     .ungroup())\n",
    "\n",
    "n = (DplyFrame(m)\n",
    "     .group_by('Demo.State')\n",
    "     .mutate(prop=(X.Total_exposed_strata/X.Total_exposed_strata.sum())*100))\n",
    "\n",
    "k = (DplyFrame(brand)\n",
    "     .filter_by(Group=\"Control\")\n",
    "     .group_by('week', 'Demo.State', 'Strata')\n",
    "     .mutate(Total_control=X.Weight.sum())\n",
    "     .ungroup()\n",
    "     .group_by('week', 'Demo.State')\n",
    "     .mutate(Total_control_strata=X.Total_control.sum())\n",
    "     .ungroup())\n",
    "\n",
    "l = (DplyFrame(k)\n",
    "     .group_by('Demo.State')\n",
    "     .mutate(prop=(X.Total_control_strata/X.Total_control_strata.sum())*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad3dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "brand_lift = pd.concat([n, l], ignore_index=True)\n",
    "\n",
    "brand_lift = (DplyFrame(brand_lift)\n",
    "              .group_by('Demo.State', 'week')\n",
    "              .mutate(lift=(X.prop - X.prop.shift(fill_value=0)))\n",
    "              .mutate(lift=X.lift.round(2)))\n",
    "\n",
    "brand_lift.loc[brand_lift['lift'].isna(), 'lift'] = 0\n",
    "\n",
    "brand_lift['lift'] = pd.to_numeric(brand_lift['lift'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e38d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pivottablejs as pt\n",
    "\n",
    "# group by c5, arrange by week, and calculate cumulative lift\n",
    "brand_lift = brand_lift.sort_values(by=['week']).groupby(['c5']).apply(\n",
    "    lambda x: x.assign(\n",
    "        increment=pd.Series([x['lift'].iloc[0]] + list(np.maximum(np.diff(x['lift']), 0))),\n",
    "        Cumulative=lambda y: np.cumsum(y['increment']),\n",
    "        cumulative=lambda z: (z['Cumulative'] - np.mean(z['Cumulative'])) / np.std(z['Cumulative'])\n",
    "    )\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# # filter by date\n",
    "# brand_lift_m = brand_lift[brand_lift['date'] >= '2023-01-05']\n",
    "# brand_lift_all = df[df['date'] >= '2023-01-05']\n",
    "\n",
    "# create heatmap using pivottablejs\n",
    "pt.pivot_ui(brand_lift, rows=['c5'], cols=['Weekname', 'week'], \n",
    "            vals='cumulative', aggregatorName='Last', rendererName='Heatmap', \n",
    "            colOrder=\"key_a_to_z\", rowOrder=\"key_a_to_z\", \n",
    "            rendererOptions={\n",
    "                'heatmap': {\n",
    "                    'colorScaleGenerator': lambda values: pt.color_scale(values, 'green')\n",
    "                }\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7300289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# create table\n",
    "table = pd.pivot_table(brand_lift_m, values='cumulative', index='creativename', columns='date')\n",
    "\n",
    "# calculate cumulative lift and maximum value per week\n",
    "d4 = brand_lift.groupby(['Weekname', 'date']).agg({'cumulative': 'last'}).reset_index()\n",
    "d5 = d4.groupby('Weekname').agg({'cumulative': 'max'}).reset_index()[1:]\n",
    "d5['Weekname'] = pd.to_datetime(d5['Weekname'], format='%m/%d/%y')\n",
    "d5['Max'] = round(d5['Max'], digits=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed2a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create line plot\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.lineplot(data=d5, x='Weekname', y='Max', color='forestgreen')\n",
    "sns.scatterplot(data=d5, x='Weekname', y='Max', color='darkgreen')\n",
    "sns.despine(left=True)\n",
    "ax.set(title='Family Dollar Brand Lift', xlabel='Weeks', ylabel='Cumulative %')\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%y'))\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d892720",
   "metadata": {},
   "outputs": [],
   "source": [
    "old = brand_lift.loc[brand_lift['date'] < pd.to_datetime(\"2022-11-28\")]\n",
    "new = brand_lift.loc[brand_lift['date'] >= pd.to_datetime(\"2022-11-28\")]\n",
    "\n",
    "old_data = old.groupby(['Weekname', 'date'])['cumulative'].last().reset_index()\n",
    "\n",
    "old_data = old_data.loc[old_data['date'] >= pd.to_datetime(\"2022-10-31\")]\n",
    "\n",
    "new_data = new.groupby(['Weekname', 'date'])['cumulative'].last().reset_index()\n",
    "\n",
    "old_data['type'] = 'Before Algo Push'\n",
    "new_data['type'] = '11/28: After Algo Push'\n",
    "\n",
    "d4 = pd.concat([old_data, new_data])\n",
    "\n",
    "sns.barplot(x='type', y='cumulative', data=d4, hue='type', palette=['forestgreen', 'red'])\n",
    "plt.title(\"Family Dollar Brand Lift\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Cumulative %\")\n",
    "plt.legend([],[], frameon=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
